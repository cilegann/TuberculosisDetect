{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 129, 313, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 129, 313, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 129, 313, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 127, 311, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 127, 311, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 127, 311, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 155, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 61, 153, 128)      73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 61, 153, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 61, 153, 128)      512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 59, 151, 128)      147584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 59, 151, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 59, 151, 128)      512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 29, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 27, 73, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 27, 73, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 27, 73, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 25, 71, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 25, 71, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 25, 71, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 23, 69, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 23, 69, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 23, 69, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 34, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 95744)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               24510720  \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 26,319,427\n",
      "Trainable params: 26,316,099\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "150/150 [==============================] - 1s 6ms/step\n",
      "loss: 0.8792193571726481\n",
      "accu: 0.660000003973643\n",
      "0 0 -> 0\n",
      "1 0 -> 0\n",
      "2 0 -> 0\n",
      "3 0 -> 0\n",
      "4 0 -> 0\n",
      "5 0 -> 1\n",
      "6 0 -> 1\n",
      "7 0 -> 0\n",
      "8 0 -> 1\n",
      "9 0 -> 0\n",
      "10 0 -> 0\n",
      "11 0 -> 1\n",
      "12 0 -> 1\n",
      "13 0 -> 0\n",
      "14 0 -> 1\n",
      "15 0 -> 1\n",
      "16 0 -> 0\n",
      "17 0 -> 0\n",
      "18 0 -> 1\n",
      "19 0 -> 0\n",
      "20 1 -> 1\n",
      "21 1 -> 0\n",
      "22 1 -> 1\n",
      "23 1 -> 1\n",
      "24 1 -> 1\n",
      "25 1 -> 1\n",
      "26 1 -> 1\n",
      "27 1 -> 1\n",
      "28 1 -> 0\n",
      "29 1 -> 0\n",
      "30 1 -> 0\n",
      "31 1 -> 1\n",
      "32 1 -> 1\n",
      "33 1 -> 1\n",
      "34 1 -> 1\n",
      "35 1 -> 0\n",
      "36 1 -> 1\n",
      "37 1 -> 0\n",
      "38 1 -> 1\n",
      "39 1 -> 0\n",
      "40 1 -> 0\n",
      "41 1 -> 0\n",
      "42 1 -> 1\n",
      "43 1 -> 1\n",
      "44 1 -> 1\n",
      "45 1 -> 1\n",
      "46 1 -> 1\n",
      "47 1 -> 0\n",
      "48 1 -> 1\n",
      "49 1 -> 1\n",
      "50 1 -> 1\n",
      "51 1 -> 0\n",
      "52 1 -> 1\n",
      "53 1 -> 1\n",
      "54 1 -> 1\n",
      "55 1 -> 2\n",
      "56 1 -> 1\n",
      "57 1 -> 1\n",
      "58 1 -> 0\n",
      "59 1 -> 1\n",
      "60 1 -> 1\n",
      "61 1 -> 1\n",
      "62 1 -> 1\n",
      "63 1 -> 1\n",
      "64 1 -> 1\n",
      "65 1 -> 0\n",
      "66 1 -> 1\n",
      "67 1 -> 0\n",
      "68 1 -> 1\n",
      "69 1 -> 1\n",
      "70 1 -> 2\n",
      "71 1 -> 0\n",
      "72 1 -> 1\n",
      "73 1 -> 2\n",
      "74 1 -> 2\n",
      "75 1 -> 1\n",
      "76 1 -> 0\n",
      "77 1 -> 0\n",
      "78 1 -> 0\n",
      "79 1 -> 0\n",
      "80 1 -> 1\n",
      "81 1 -> 2\n",
      "82 1 -> 1\n",
      "83 1 -> 1\n",
      "84 1 -> 1\n",
      "85 1 -> 2\n",
      "86 1 -> 1\n",
      "87 1 -> 1\n",
      "88 1 -> 2\n",
      "89 1 -> 1\n",
      "90 1 -> 1\n",
      "91 1 -> 1\n",
      "92 1 -> 1\n",
      "93 1 -> 1\n",
      "94 1 -> 1\n",
      "95 1 -> 1\n",
      "96 1 -> 1\n",
      "97 1 -> 1\n",
      "98 1 -> 1\n",
      "99 1 -> 0\n",
      "100 1 -> 0\n",
      "101 1 -> 1\n",
      "102 1 -> 2\n",
      "103 1 -> 1\n",
      "104 1 -> 0\n",
      "105 1 -> 1\n",
      "106 1 -> 1\n",
      "107 1 -> 1\n",
      "108 1 -> 1\n",
      "109 1 -> 0\n",
      "110 1 -> 0\n",
      "111 1 -> 1\n",
      "112 1 -> 0\n",
      "113 1 -> 0\n",
      "114 1 -> 1\n",
      "115 1 -> 0\n",
      "116 1 -> 0\n",
      "117 1 -> 1\n",
      "118 1 -> 0\n",
      "119 1 -> 0\n",
      "120 1 -> 1\n",
      "121 1 -> 0\n",
      "122 1 -> 1\n",
      "123 1 -> 1\n",
      "124 1 -> 0\n",
      "125 1 -> 0\n",
      "126 1 -> 1\n",
      "127 1 -> 1\n",
      "128 1 -> 0\n",
      "129 1 -> 1\n",
      "130 2 -> 2\n",
      "131 2 -> 2\n",
      "132 2 -> 2\n",
      "133 2 -> 2\n",
      "134 2 -> 2\n",
      "135 2 -> 2\n",
      "136 2 -> 2\n",
      "137 2 -> 2\n",
      "138 2 -> 2\n",
      "139 2 -> 2\n",
      "140 2 -> 2\n",
      "141 2 -> 2\n",
      "142 2 -> 1\n",
      "143 2 -> 2\n",
      "144 2 -> 2\n",
      "145 2 -> 2\n",
      "146 2 -> 2\n",
      "147 2 -> 2\n",
      "148 2 -> 2\n",
      "149 2 -> 2\n",
      "[[0.6        0.4        0.        ]\n",
      " [0.30909091 0.61818182 0.07272727]\n",
      " [0.         0.05       0.95      ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import utils as np_utils\n",
    "from keras import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.layers import Activation,Dense,Dropout,MaxPooling2D,Flatten,Conv2D,GlobalMaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.optimizers import rmsprop,adam,SGD,Adadelta\n",
    "import keras.losses\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import platform\n",
    "\n",
    "from src.evaluate_tools import cam,plot_confusion_matrix\n",
    "#train : python3 scriptname train\n",
    "#predict: python3 scriptname predict [modelname]\n",
    "#saliencymap: python3 scriptname cam [modelname] [dataset] [portion] [amount] [save/show]\n",
    "\n",
    "positive_weigt=15.\n",
    "polluted_weight=4.5\n",
    "negative_weight=1.4\n",
    "# if 'balance' in os.sys.argv:\n",
    "#     positive_weigt=1\n",
    "#     polluted_weight=1\n",
    "#     negative_weight=1\n",
    "height=131\n",
    "width=315#420 #2.1\n",
    "epoch=150#200 #1\n",
    "vali_split=0.3\n",
    "\n",
    "host = platform.node()  #cilegann-PC / ican-1080ti\n",
    "mode = os.sys.argv[1] #train / predict / saliencymap\n",
    "gpu='single'\n",
    "\n",
    "model_to_load=''\n",
    "if(mode=='predict' or mode=='cam'):\n",
    "    model_to_load=os.sys.argv[2]\n",
    "if(host=='ican-1080ti'):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    session = tf.Session(config=config)\n",
    "    KTF.set_session(session)\n",
    "    batch_size=64\n",
    "    if('balance' in os.sys.argv):\n",
    "        batch_size=63\n",
    "elif(host=='cilegann-PC'):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    session = tf.Session(config=config)\n",
    "    KTF.set_session(session)\n",
    "    batch_size=32\n",
    "    if('balance' in os.sys.argv):\n",
    "        batch_size=30\n",
    "\n",
    "train_mapping_file='./data/CNN_x_y_mapping.csv'\n",
    "vali_mapping_file='./data/CNN_vali_x_y_mapping.csv'\n",
    "\n",
    "polluted_train_basedir='./data/polluted'\n",
    "positive_train_basedir='./data/positive'\n",
    "negative_train_basedir='./data/negative'\n",
    "polluted_vali_basedir='./data/vali/polluted'\n",
    "positive_vali_basedir='./data/vali/positive'\n",
    "negative_vali_basedir='./data/vali/negative'\n",
    "\n",
    "index = 0\n",
    "vali_index = 0\n",
    "\n",
    "train_x_file_list = []\n",
    "train_x = []\n",
    "train_y = []\n",
    "train_start_index=[-1,-1,-1]\n",
    "train_end_index=[-1,-1,-1]\n",
    "train_len=[-1,-1,-1]\n",
    "\n",
    "vali_x_file_list = []\n",
    "vali_x=[]\n",
    "vali_y = []\n",
    "prob_y=[]\n",
    "vali_start_index=[-1,-1,-1]\n",
    "vali_end_index=[-1,-1,-1]\n",
    "vali_len=[-1,-1,-1]\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "def create_x_y_mapping(train_or_vali):\n",
    "    basedir_list=[]\n",
    "    if(train_or_vali=='train'):\n",
    "        mapping_file=train_mapping_file\n",
    "        basedir_list=[negative_train_basedir,positive_train_basedir,polluted_train_basedir]\n",
    "    else:\n",
    "        mapping_file=vali_mapping_file\n",
    "        basedir_list=[negative_vali_basedir,positive_vali_basedir,polluted_vali_basedir]\n",
    "    with open(mapping_file,'w') as f:\n",
    "        f.write(\"file_path,label\\n\")\n",
    "        for i,b in enumerate(basedir_list):\n",
    "            for root, directs,filenames in os.walk(b):\n",
    "                for filename in filenames:\n",
    "                    if 'txt' not in filename:\n",
    "                        pathName=os.path.join(root,filename)\n",
    "                        if( ('jpg' in pathName) or ('png' in pathName) ):\n",
    "                            f.write(pathName+','+str(i)+'\\n')\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "def read_x_y_mapping(train_or_vali,shuffle):\n",
    "    if(train_or_vali=='train'):\n",
    "        global train_x_file_list\n",
    "        global train_y\n",
    "        global train_start_index\n",
    "        global train_end_index\n",
    "        global train_len\n",
    "        file_list=[]\n",
    "        y=[]\n",
    "        mapping_file=train_mapping_file\n",
    "    else:\n",
    "        global vali_x_file_list\n",
    "        global vali_y\n",
    "        global vali_start_index\n",
    "        global vali_end_index\n",
    "        global vali_len\n",
    "        file_list=[]\n",
    "        y=[]\n",
    "        mapping_file=vali_mapping_file\n",
    "    if(not os.path.exists(mapping_file)):\n",
    "        create_x_y_mapping(train_or_vali)\n",
    "    with open(mapping_file,'r') as f:\n",
    "        next(f)\n",
    "        lines=f.readlines()\n",
    "        for line in lines:\n",
    "            file_list.append(line.split(',')[0])\n",
    "            y.append(line.split(',')[1][:-1])\n",
    "    if(shuffle):\n",
    "        c=list(zip(file_list,y))\n",
    "        random.shuffle(c)\n",
    "        file_list,y=zip(*c)\n",
    "    else:\n",
    "        s0=y.index('0')\n",
    "        s1=y.index('1')\n",
    "        s2=y.index('2')\n",
    "        e0=s1-1\n",
    "        e1=s2-1\n",
    "        e2=len(y)-1\n",
    "        l0=e0-s0+1\n",
    "        l1=e1-s1+1\n",
    "        l2=e2-s2+1\n",
    "    if(train_or_vali=='train'):\n",
    "        train_x_file_list=file_list\n",
    "        train_y=np_utils.to_categorical(np.array(y),3)\n",
    "        if not shuffle:\n",
    "            train_start_index=[s0,s1,s2]\n",
    "            train_end_index=[e0,e1,e2]\n",
    "            train_len=[l0,l1,l2]\n",
    "    else:\n",
    "        vali_x_file_list=file_list\n",
    "        vali_y=np_utils.to_categorical(np.array(y),3)\n",
    "        if not shuffle:\n",
    "            vali_start_index=[s0,s1,s2]\n",
    "            vali_end_index=[e0,e1,e2]\n",
    "            vali_len=[l0,l1,l2]\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "def load_all_valid():\n",
    "    global vali_x\n",
    "    vali_x = np.zeros([len(vali_x_file_list), height, width, 3])\n",
    "    for i,f in enumerate(vali_x_file_list):\n",
    "        vali_x[i]=Image.open(f).resize([width,height])\n",
    "    vali_x=vali_x.astype('float64')\n",
    "    vali_x/=255.\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "def generate_valid_from_train():\n",
    "    global train_x_file_list\n",
    "    global train_y\n",
    "    global vali_x_file_list\n",
    "    global vali_y\n",
    "    vali_x_file_list = train_x_file_list[ :math.ceil(len(train_x_file_list)*vali_split) ]\n",
    "    vali_y = train_y [ :math.ceil(len(train_x_file_list)*vali_split) ]\n",
    "    train_x_file_list = train_x_file_list [math.floor(len(train_x_file_list)*vali_split):]\n",
    "    train_y = train_y [math.floor(len(train_x_file_list)*vali_split):]\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "def resize_preprocessing(data,label):\n",
    "    data=data.resize([width,height])\n",
    "    data = np.asarray(data)\n",
    "    data = data.astype('float64')\n",
    "    if (random.random() > 0.5 and int(label[1])==1):\n",
    "        data = cv2.flip(data, 1)\n",
    "    data/=255.\n",
    "    return data\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "def data_generator(is_training):\n",
    "    global index\n",
    "    global vali_index\n",
    "    while(1):\n",
    "        if is_training == True:\n",
    "            if index + batch_size > len(train_x_file_list):\n",
    "                index = 0\n",
    "            file_list = train_x_file_list[index:index + batch_size]\n",
    "            label_list = train_y[index:index + batch_size]\n",
    "            index += batch_size\n",
    "        else:\n",
    "            if vali_index + batch_size > len(vali_x_file_list):\n",
    "                vali_index = 0\n",
    "            file_list = vali_x_file_list[vali_index:vali_index + batch_size]\n",
    "            label_list = vali_y[vali_index:vali_index + batch_size]\n",
    "            vali_index += batch_size\n",
    "\n",
    "        output = np.zeros([batch_size, height,width, 3])\n",
    "        for i in range(batch_size):\n",
    "            output[i]=resize_preprocessing(Image.open(file_list[i]),label_list[i])\n",
    "\n",
    "        yield output, label_list\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "def data_generator_balance(is_training):\n",
    "    if is_training:\n",
    "        s=train_start_index[:]\n",
    "        e=train_end_index[:]\n",
    "        l=train_len[:]\n",
    "    else:\n",
    "        s=vali_start_index[:]\n",
    "        e=vali_end_index[:]\n",
    "        l=vali_len[:]\n",
    "    flag=[0,0,0]\n",
    "    while(1):\n",
    "        file_list=[]\n",
    "        label_list=[]\n",
    "        for b in range(int(batch_size/3)):\n",
    "            for i in range(3):\n",
    "                index=flag[i]+s[i]\n",
    "                if is_training:\n",
    "                    file_list.append(train_x_file_list[index])\n",
    "                    label_list.append(train_y[index])\n",
    "                else:\n",
    "                    file_list.append(vali_x_file_list[index])\n",
    "                    label_list.append(vali_y[index])\n",
    "                flag[i]+=1\n",
    "                if(flag[i]>=l[i]):\n",
    "                    flag[i]=0\n",
    "\n",
    "        # c=list(zip(file_list,label_list))\n",
    "        # random.shuffle(c)\n",
    "        # file_list,label_list=zip(*c)\n",
    "        label_list=np.asarray(label_list)\n",
    "        output = np.zeros([batch_size, height,width, 3])\n",
    "        for i in range(batch_size):\n",
    "            output[i]=resize_preprocessing(Image.open(file_list[i]),label_list[i])\n",
    "        yield(output,label_list)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(height,width,3),data_format='channels_last'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(Conv2D(128,(3,3),strides=(1,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128,(3,3),strides=(1,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "\n",
    "    # model.add(Conv2D(1024,(3,3),strides=(1,1)))\n",
    "    # model.add(Activation('relu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Conv2D(1024,(3,3),strides=(1,1)))\n",
    "    # model.add(Activation('relu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Conv2D(1024,(3,3),strides=(1,1)))\n",
    "    # model.add(Activation('relu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(MaxPooling2D(2,2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "def training(model):\n",
    "    es=EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "    #rlr=ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "    mck=ModelCheckpoint(filepath='cnn_model_best.h5',monitor='val_loss',save_best_only=True)\n",
    "    tb = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "    if(host=='ican-1080ti' and gpu == 'both'):\n",
    "        model = multi_gpu_model(model, gpus=2)\n",
    "    class_weight = {0: negative_weight,1: positive_weigt,2: polluted_weight}\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    adadelta=Adadelta()\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=adadelta,metrics=['acc'])\n",
    "    model.fit_generator(data_generator(True) if 'balance' not in os.sys.argv else data_generator_balance(True),validation_data=(vali_x,vali_y),validation_steps=1,steps_per_epoch=len(train_x_file_list)//batch_size, epochs=epoch,callbacks=[mck,es,tb],class_weight=class_weight)\n",
    "    model.save('cnn_model.h5')\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "def predict():\n",
    "    global vali_x\n",
    "    global model_to_load\n",
    "    global prob_y\n",
    "    global model_to_load\n",
    "    if(model_to_load==''):\n",
    "        model_to_load='cnn_model_best.h5'\n",
    "    model=load_model(model_to_load)\n",
    "    model.summary()\n",
    "    read_x_y_mapping('vali',False)\n",
    "    load_all_valid()\n",
    "    loss, accuracy = model.evaluate(vali_x, vali_y)\n",
    "    print(\"loss: \"+str(loss))\n",
    "    print(\"accu: \"+str(accuracy))\n",
    "    prob_y = model.predict(vali_x)\n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "    with open('result.csv','w') as file:\n",
    "        file.write(\"filename,real_value,pred_value\\n\")\n",
    "        for i,p in enumerate(vali_x_file_list):\n",
    "            file.write(p+\",\"+str(np.argmax(vali_y[i]))+\",\"+str(np.argmax(prob_y[i]))+'\\n')\n",
    "            print(str(i)+\" \"+ str(np.argmax(vali_y[i])) +\" -> \"+str(np.argmax(prob_y[i])))\n",
    "    y_true=np.argmax(vali_y,axis=1)\n",
    "    y_pred=np.argmax(prob_y,axis=1)\n",
    "    labels=[\"negative\", \"positive\", \"polluted\"]\n",
    "    plot_confusion_matrix(y_true,y_pred,classes=labels)\n",
    "        \n",
    "    return y_true,y_pred\n",
    "\n",
    "        \n",
    "###################################################################################\n",
    "\n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes\n",
    "\n",
    "def cam(filename,img,label,model,backprop_modifier='guided'):\n",
    "    shutil.rmtree(\"./cam/\")\n",
    "    os.mkdir(\"cam\")\n",
    "    np.seterr(divide='ignore',invalid='ignore')\n",
    "    \n",
    "    filename='./cam/'+filename+'.jpg'\n",
    "    print(filename)\n",
    "    heatmap = visualize_cam(model, layer_idx=-1, filter_indices=label, seed_input=img,backprop_modifier=backprop_modifier)\n",
    "    jet_heatmap = np.uint8(cm.jet(heatmap)[..., :3] * 255)\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2,2)\n",
    "    im1=plt.imshow(img, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    im2 = plt.imshow(heatmap,  alpha=.4, interpolation='bilinear')\n",
    "    plt.savefig(filename,dpi=300)\n",
    "\n",
    "\n",
    "def main():\n",
    "    model=load_model('./cnn_model_best.h5')\n",
    "    imgs=[]\n",
    "    y_true,y_pred=predict()\n",
    "    for i,img in enumerate(imgs):\n",
    "        cam(str(i)+'_'+y_pred[i],img,y_pred[i],model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
